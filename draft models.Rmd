---
title: "messing around"
author: "Ricky Heinrich & Vimaljeet Singh"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## Goal:
Predict the number of bikes rented per hour, given predictors:
- time of day
- time of year
- weather
- etc

Models to investigate:
- lm
- poisson glm
- decision trees, random forests
- non parametric
- ?

How to decide which model is best:
- BIC
- MSE
- training values vs testing values
- ?

Which predictor is most important?
- find out via p-values ?
- gini index in random forest
- ?


## setting up data
```{r, echo=FALSE, results='hide', include=FALSE}
library(tidyverse)
library(ggplot2)

dffull <- read.csv("Bike-Sharing-Dataset/hour.csv", stringsAsFactors = TRUE)
dffull$rawtemp = dffull$temp*47-8 # converting temp to raw form
dffull$rawatemp = dffull$atemp*66-16 # converting atemp to raw
dffull$rawhum = dffull$hum*100 # converting hum to raw form
dffull$rawwindspeed = dffull$windspeed*67 # converting windspeed to raw form 

```

# Removing variables I don't care about
```{r}
dflessvar <- subset(dffull, select = -c(instant, dteday, yr,temp, atemp, hum, windspeed, rawatemp, workingday))
  
# converting some to factors
# columns that should be factors
cols <- c("season", "mnth", "hr","holiday","weekday","weathersit")
dflessvar[,cols] <- data.frame(lapply(dflessvar[cols], as.factor))


# setting levels of factors
levels(dflessvar$season) <- c("winter", "spring", "summer", "fall")
levels(dflessvar$mnth) <- c("Jan", "Feb", "Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec")
levels(dflessvar$holiday) <- c("Not Holiday", "Holiday")
levels(dflessvar$weekday) <- c("Sun","Mon","Tues","Wed","Thurs","Fri","Sat")
#levels(dflessvar$workingday) <- c("Not working day","Working day")
levels(dflessvar$weathersit) <- c("Clear","Misty","Light precip", "heavy precip")

set.seed(2023)
sample.index <- sample(nrow(dflessvar),nrow(dflessvar)*0.60, replace = FALSE)
df <- dflessvar[sample.index,]
df.test <- dflessvar[-sample.index,]
```

Need to make sure stuff is factoring properly .... like that when it factors the levels mean the same thing I think they mean, so we don't fuck up analysis later. I forget the code to double check the matching of the levels and factors 


## linear regression ?
```{r}
# response variable full count, removing casual and registered
# could do another model with just casual then just registered to see if the variables affect them differently
lmmod <- lm(cnt~., data = df[,-c(7,8)])
#summary(lmmod)
```
How to we interpret this intercept? Like if all the betas are 0, we get than intercept, does that mean all the binary variables that have 0s in them are the only ones that are 'inplace' ?

I don't know why workingday is showing as NA, something going wrong somewhere. It looks like a lot of variables are significant, F test coming up with tiny p-value (need to double check how to interpret that). All hours are significant but not all months ... kinda funny. Also unsure how to interpret like if january has effect, or any of the 'first' factors. 

Should run the tests from John's class to see if linear model fits, like nmpreg or whatever. Run diagnostics too, show normality conditions don't hold.

Show predicted values come out negative (Vimal shows this)

Should we do cross validation? 

```{r}
plot(lmmod)
```
we see that some values fit under 0, so despite a decent R^2 this is not a realistic model. To deal with this, we want to consider a Poisson model, where the response variable is a count that can never be negative.

```{r}
predlmmod <- predict(lmmod,df.test[,-c(7,8,9)], type="response")

(mselmmod <- mean((df.test[,9] - predlmmod)^2))

```

```{r}
poismod <- glm(cnt~., data = df[,-c(7,8)], family = poisson)
summary(poismod)
```
null deviance: if only interecept. 

```{r}
plot(poismod)
```
```{r}
predpois <- predict(poismod, df.test[,-c(7,8,9)], type="response")
 
(msepois <- mean((df.test[,9] - predpois)^2))
```



```{r}
quasipoismod <- glm(cnt~., data =  df[,-c(7,8)], family = quasipoisson)
summary(quasipoismod)
plot(quasipoismod)
```
```{r}
predquasi <- predict(quasipoismod, df.test[,-c(7,8,9)], type="response")
 
(msequasi <- mean((df.test[,9] - predquasi)^2))



```



## random forest decision tree?

What are the assumptions of random forest again ?
- 
```{r}
library(randomForest)
set.seed(2023)
rdforestmod <- randomForest(cnt~., data = df[,-c(7,8)], importance=TRUE)
varImpPlot(rdforestmod)
rdforestmod


predrf <- predict(rdforestmod, df.test[,-c(7,8,9)], type="response")
 
(mserf <- mean((df.test[,9] - predrf)^2))
 

sum(predrf < 0)
```
## predictions
```{r}
predtable <- data.frame(Model = c("LM", "GLM (Poisson)","GLM (quasiPoisson)"," Random forest"),
                 MSE = c(mselmmod, msepois, msequasi, mserf ))
predtable

```


# test if lm is bad
```{r}
library(lmtest)
reset(lmmod)
```


## see if we can do one of those spline things or non parametrics since they are john's fav
```{r  cache=TRUE}
library(np)
#npmod <- npregbw(cnt~season+mnth+hr+holiday+weekday+weathersit+rawtemp+rawhum+rawwindspeed, data = df[,-c(7,8)], regtype="ll", bwmethod="cv.ls")
#modnp <- npreg(bws = npmod)

```


- 


- hypothesis: model improves when separating prediction for casual vs registered users
- hypothesis: we are able to predict the count of bikes rented in a given hour given the predictor variables (weather, calendar date and time, etc)


# question list:
from leverage plot, should we investigate the big points, how to interpret them



## separating casual and regsitered to see differences in models

```{r}
# linear model casual
lmmodcas <- lm(casual~., data = df[,-c(8,9)])
summary(lmmodcas)
plot(lmmodcas)
predlmmodcas <- predict(lmmodcas,df.test[,-c(7,8,9)], type="response")
mselmmodcas <- mean((df.test[,7] - predlmmodcas)^2)

colnames(df)

# linear model registered
lmmodreg <- lm(registered~., data = df[,-c(7,9)])
summary(lmmodreg)
plot(lmmodreg)
predlmmodreg <- predict(lmmodreg,df.test[,-c(7,8,9)], type="response")
mselmmodreg <- mean((df.test[,8] - predlmmodreg)^2)


# poisson casual
poismodcas <- glm(casual~., data = df[,-c(9,8)], family = poisson)
summary(poismodcas)
predpoiscas <- predict(poismodcas, df.test[,-c(7,8,9)], type="response")
(msepoiscas <- mean((df.test[,7] - predpoiscas)^2))

# poisson registered
poismodreg <- glm(registered~., data = df[,-c(7,9)], family = poisson)
summary(poismodreg)
predpoisreg <- predict(poismodreg, df.test[,-c(7,8,9)], type="response")
(msepoisreg <- mean((df.test[,8] - predpoisreg)^2))

# quasi cas
quasipoismodcas <- glm(casual~., data =  df[,-c(8,9)], family = quasipoisson)
summary(quasipoismodcas)
plot(quasipoismodcas)
predquasicas <- predict(quasipoismodcas, df.test[,-c(7,8,9)], type="response")
(msequasicas <- mean((df.test[,7] - predquasicas)^2))

# quasi reg
quasipoismodreg <- glm(registered~., data = df[,-c(7,9)], family = quasipoisson)
summary(quasipoismodreg)
predquasireg <- predict(quasipoismodreg, df.test[,-c(7,8,9)], type="response")
(msequasireg <- mean((df.test[,8] - predquasireg)^2))

# rf cas
set.seed(2023)
rdforestmodcas <- randomForest(casual~., data = df[,-c(9,8)], importance=TRUE)
varImpPlot(rdforestmodcas)
rdforestmod
predrfcas <- predict(rdforestmodcas, df.test[,-c(7,8,9)], type="response")
(mserfcas <- mean((df.test[,7] - predrfcas)^2))

# rf reg
set.seed(2023)
rdforestmodreg <- randomForest(registered~., data = df[,-c(7,9)], importance=TRUE)
varImpPlot(rdforestmodreg)
rdforestmodreg
predrfreg <- predict(rdforestmodreg, df.test[,-c(7,8,9)], type="response")
(mserfreg <- mean((df.test[,8] - predrfreg)^2))


# adding to dataframe of MSEs
predtable$MSEcas <- c(mselmmodcas, msepoiscas, msequasicas, mserfcas)
predtable$MSEreg <- c(mselmmodreg, msepoisreg, msequasireg, mserfreg)
``` 

``` {r}
library(np)
npmod <- npregbw(casual~season+mnth+hr+holiday+weekday+weathersit+rawtemp+rawhum+rawwindspeed, data = df[,-c(9,8)], regtype="ll", bwmethod="cv.ls")
bw <- npregbw(casual~season+mnth+hr+holiday+weekday+weathersit+rawtemp+rawhum+rawwindspeed, data = df[,-c(9,8)], bws=c(0.5,0.5,0.5,0.5,0.5,0.5,2,6,4),
              bandwidth.compute=FALSE)
modnp <- npreg(bws = bw)
summary(modnp)
prednpcas <- predict(modnp, df.test[,-c(7,8,9)])
(msenpcas <- mean((df.test[,8] - prednpcas)^2))
npsigtest(modnp, boot.num = 10)

modnptest <- npreg(bws = bw,exdat =  df.test[,-c(7,8,9)])
summary(modnptest)

library(npreg)
predict.gsm
```

```{r}
plot(df$casual, df$rawtemp)
npmodnum <- npregbw(casual~rawtemp, data = df[,-c(9,8)], regtype="ll", bwmethod="cv.ls")
modnpnum <- npreg(bws = npmodnum)
summary(modnpnum)

npmodnum3 <- npregbw(casual~rawtemp+rawhum+rawwindspeed, data = df[,-c(9,8)], regtype="ll", bwmethod="cv.ls")
modnpnum3 <- npreg(bws = npmodnum3)
summary(modnpnum3)


```


# Results
As we've seen in the EDA (idk if we can mention like, this, b/c stakeholder will probs not refer to EDA? like if we were to publish this 'paper', so might just need to give more context). We see from the estimation vs actual plot, 2012 has overal higher values. The variance due to the second year having wildly different values suggests that this data is not the best to train as we want it; we would need more years to analyze growing trends, to better forecast and model future trends. This is reflected in our high errors ? 

Is it dumb to remove the year then? hard to forecast future growth with just 2 years, but maybe could assume the growth in 2013 is the same from 2011 to 2013 ..
Or just mention it in limitations, like have a big section talking about limitations and how forecasting would have been better but we didn't actually do that in this program and I forgot about my forecasting class from undergrad until rn, when it is too late, plus limitations in dataset kinda prevent from doing so.

## Conclusions



